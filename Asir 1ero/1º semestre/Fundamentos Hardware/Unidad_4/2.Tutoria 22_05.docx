# Resumen: Tutoría de Fundamentos de Hardware - Procesadores Especializados e IA (22/05/2025)

## Introducción y continuación de la clase principal

Esta tutoría complementó la clase principal sobre procesadores, enfocándose en aplicaciones específicas de procesadores especializados en inteligencia artificial y procesamiento de datos, así como en la demostración práctica de modelos de aprendizaje automático.

## Ley de Moore y futuro de los procesadores

- **Ley de Moore**: Se discutió cómo esta ley (que establece que el número de transistores en un microprocesador se duplica cada dos años) sigue cumpliéndose hasta ahora
- **Limitaciones físicas**: Se mencionó que eventualmente se alcanzará un límite físico donde no se podrán hacer transistores más pequeños
- **Alternativas futuras**: La computación cuántica se presentó como la posible solución cuando se llegue al límite físico de miniaturización
- **Qubits vs Bits clásicos**: Se explicó brevemente que mientras un bit clásico solo puede tener valores de 0 o 1, un qubit puede estar en múltiples estados simultáneamente, permitiendo realizar muchas más operaciones

## Demostración práctica: Google Colab y procesamiento de IA

La mayor parte de la tutoría consistió en una demostración práctica utilizando Google Colab, mostrando:

### Entrenamiento de un modelo de reconocimiento de imágenes
- **Dataset utilizado**: Imágenes numéricas (del 0 al 9) para clasificación
- **Arquitectura del modelo**: Red neuronal convolucional (CNN) para clasificación de imágenes
- **Componentes del proceso**:
  - Carga y preparación del dataset
  - Creación de la arquitectura de la red neuronal
  - Configuración de capas convolucionales, pooling y dropout
  - Entrenamiento del modelo por épocas
  - Evaluación de resultados con matriz de confusión

### Comparación entre CPU y GPU para entrenamiento
- **Rendimiento de CPU**: Se demostró que entrenando con CPU, cada época tardaba aproximadamente 15 minutos
- **Rendimiento de GPU**: Al cambiar a GPU, el mismo entrenamiento se realizó en aproximadamente 1 minuto
- **Diferencia de rendimiento**: Se destacó que la GPU era aproximadamente 15 veces más rápida para este tipo de tareas
- **Aplicación práctica**: Se explicó por qué las GPUs son esenciales en el desarrollo de IA y machine learning

### Modelos pre-entrenados vs modelos desde cero
- **Ventajas de modelos pre-entrenados**: Se mostró cómo un modelo pre-entrenado (EfficientB1) comenzaba con una precisión mucho mayor (70%) que un modelo desde cero (40%)
- **Transfer learning**: Se explicó cómo se pueden aprovechar modelos pre-entrenados eliminando solo las capas finales para adaptarlos a nuevas tareas

## Aplicaciones prácticas de la IA

El profesor comentó sobre varias aplicaciones prácticas de estos modelos:
- **Detección de fraudes bancarios**: Análisis de patrones en transacciones
- **Reconocimiento de animales**: Cámaras en bosques que detectan especies específicas
- **Seguridad**: Sistemas inteligentes para bancos y seguros
- **Generación de contenido**: Modelos de texto a vídeo como "One" (competidor de Sora)

## Recursos para aprendizaje e implementación

Se mencionó Hugging Face como recurso fundamental:
- **Hugging Face**: Presentada como "el Santo Grial" de las inteligencias artificiales actuales
- **Comunidad y repositorio**: Lugar donde se comparten modelos de IA de código abierto
- **Accesibilidad**: Se destacó que muchos modelos pueden utilizarse gratuitamente
- **Implementación local**: Se discutió sobre los requisitos mínimos para ejecutar algunos modelos (GPU de 6GB)

## Reflexión final sobre el futuro

La tutoría concluyó con una reflexión sobre cómo la inteligencia artificial y los modelos especializados están transformando nuestra realidad, con la certeza de que esta tendencia no se detendrá y que debemos adaptarnos a ella.

Los estudiantes mostraron especial interés en las aplicaciones prácticas y en la posibilidad de implementar estos modelos localmente con recursos limitados, así como en explorar Hugging Face como recurso para sus futuros proyectos.